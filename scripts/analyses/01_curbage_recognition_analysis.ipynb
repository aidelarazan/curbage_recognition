{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 curbage_recognition data Cleaning\n",
    "### Zachariah M. Reagh & Angelique I. Delarazan\n",
    "#### 01/31/2022\n",
    "\n",
    "Generates csv files: \n",
    "1. Calculates hits, misses, false, alarms, and correct rejects for each subject for each domain type (Narrative v. Perceptual)\n",
    "2. Output csv files based on group (Younger v. Older Adults)\n",
    "3. Appends groups and outpust csv files for further analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from itertools import islice\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Volumes/GAMMA/curbage_behavioral/experiment1/'\n",
    "data_dir = os.path.join(base_dir, f'data/recognition/')\n",
    "output_dir = os.path.join(base_dir, f'analyses/recognition/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate hits, misses, false alarms, and correct rejections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Older Adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in older adults' individual data and create a list\n",
    "sublist_older = pd.read_csv(os.path.join(base_dir, 'code/sub-all_group-older_desc-subject_list.txt'), header=None)\n",
    "sublist_older = sublist_older[0].values.tolist()\n",
    "sublist_older"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Narrative Domain Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all subjects on list and create output file, calculating subject's performance for the Narrative Task\n",
    "Z = norm.ppf\n",
    "\n",
    "sub_all_group_older_desc_narrative = pd.DataFrame(columns=['subject', 'target_hit', 'lure_cr','foil_cr'])\n",
    "\n",
    "for subject in sublist_older: \n",
    "    narrative_summary = open(os.path.join(output_dir, f'sub-{subject}_group-older_task-recognition_desc-narrative_results.txt'), 'w')\n",
    "    narrative_summary.write('subject: %d\\n' %(subject))\n",
    "    narrative_summary.write('performance_summary\\n\\n\\n\\nraw_data\\n\\n')\n",
    "    narrative_summary.write('target,target_hit,target_miss,lure,lure_cr,lure_fa,foil,foil_cr,foil_fa,junk\\n')\n",
    "    \n",
    "    performance=[]\n",
    "    target=0\n",
    "    target_hit=0\n",
    "    target_miss=0\n",
    "    lure=0\n",
    "    lure_cr=0\n",
    "    lure_fa=0\n",
    "    foil=0\n",
    "    foil_cr=0\n",
    "    foil_fa=0\n",
    "    junk=0\n",
    "    \n",
    "    with open(os.path.join(data_dir, f'sub-{subject}_group-older_task-recognition_desc-narrative.txt')) as fd:\n",
    "        for line in islice(csv.reader(fd), 5, None):\n",
    "            performance.append([line[0],line[1],line[2],line[3],line[4]])\n",
    "            if 't' in line[1]:\n",
    "                target+=1\n",
    "            if 't' in line[1] and line[3]=='t':\n",
    "                target_hit+=1\n",
    "            if 't' in line[1] and line[3]=='f':\n",
    "                target_miss+=1\n",
    "            # Start move to lure trials\n",
    "            if 's' in line[1]:\n",
    "                lure+=1\n",
    "            if 's' in line[1] and line[3]=='t':\n",
    "                lure_fa+=1\n",
    "            if 's' in line[1] and line[3]=='f':\n",
    "                lure_cr+=1\n",
    "            if 'n' in line[1]:\n",
    "                foil+=1\n",
    "            if 'n' in line[1] and line[3]=='t':\n",
    "                foil_fa+=1\n",
    "            if 'n' in line[1] and line[3]=='f':\n",
    "                foil_cr+=1\n",
    "            if line [1] == '':\n",
    "                junk+=1\n",
    "            \n",
    "    target_hit = target_hit\n",
    "    target_miss = target_miss\n",
    "    lure_cr = lure_cr\n",
    "    lure_fa = lure_fa\n",
    "    target_hit_rate = target_hit / (target)\n",
    "    fa_cr_rate = foil_cr / (foil)\n",
    "    target_miss_rate = target_miss/target\n",
    "    lure_cr_rate = lure_cr/lure\n",
    "    lure_fa_rate = lure_fa/lure\n",
    "    foil_cr_rate = foil_cr/foil\n",
    "    foil_fa_rate = foil_fa/foil\n",
    "    cr = lure_cr + foil_cr\n",
    "    cr_rate = (lure_cr + foil_cr)/(lure + foil)\n",
    "    fa = lure_fa + foil_fa\n",
    "    fa_rate = (lure_fa + foil_fa)/(lure + foil)\n",
    "    \n",
    "    if target_hit_rate == 1: \n",
    "        target_hit_rate = (target - 0.5) / (target)\n",
    "    if target_hit_rate == 0: \n",
    "        target_hit_rate = 0.5 / (target)\n",
    "        \n",
    "    if foil_fa_rate == 1: \n",
    "        foil_fa_rate = (foil - 0.5) / (foil)\n",
    "    if foil_fa_rate == 0: \n",
    "        foil_fa_rate = 0.5 / (foil)    \n",
    "    \n",
    "    dprime = Z(target_hit_rate) - Z(foil_fa_rate)\n",
    "    dprime_lures = Z(target_hit_rate) - Z(lure_fa_rate)\n",
    "    \n",
    "    LDI = lure_cr_rate - target_miss_rate\n",
    "    \n",
    "    beta = math.exp((Z(fa_rate)**2 - Z(target_hit_rate)**2) / 2)\n",
    "    c = -(Z(target_hit_rate) + Z(fa_rate)) / 2\n",
    "    ad = norm.cdf(dprime / math.sqrt(2))\n",
    "    \n",
    "    # Append our big data frame with each subject's data\n",
    "    \n",
    "    sub_all_group_older_desc_narrative = sub_all_group_older_desc_narrative.append(pd.DataFrame\\\n",
    "    ({'subject': subject, 'target_hit': target_hit, 'target_miss': target_miss,\\\n",
    "      'lure_cr': lure_cr, 'lure_fa': lure_fa,\\\n",
    "      'foil_cr': foil_cr, 'foil_fa':foil_fa,\\\n",
    "      'target_hit_rate': target_hit_rate, 'lure_cr_rate': lure_cr_rate,'foil_cr_rate': foil_cr_rate,\\\n",
    "      'lure_fa_rate': lure_fa_rate, 'foil_fa_rate':foil_fa_rate,\\\n",
    "      'cr': cr, 'cr_rate': cr_rate, 'fa': fa,'fa_rate': fa_rate,\\\n",
    "      'dprime':dprime, 'dprime_lures':dprime_lures, 'LDI':LDI, 'beta':beta, 'c':c, 'ad':ad}, index=[0]), ignore_index=True)\n",
    "\n",
    "    #Append performance summary file\n",
    "    narrative_summary.write(\"%d,%d,%d,%d,%d,%d,%d,%d,%d,%d\\n\\n\\n\\n\" %(target,target_hit,target_miss,lure,lure_cr,lure_fa,foil,foil_cr,foil_fa,junk))\n",
    "    narrative_summary.write(\"targets\\n\\ntarget_hit_rate,target_miss_rate\\n\")\n",
    "    narrative_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(target_hit_rate,target_miss_rate))\n",
    "    narrative_summary.write(\"lures\\n\\nlure_cr_rate,lure_fa_rate\\n\")\n",
    "    narrative_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(lure_cr_rate,lure_fa_rate))\n",
    "    narrative_summary.write(\"foils\\n\\nfoil_cr_rate,foil_fa_rate\\n\")\n",
    "    narrative_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(foil_cr_rate,foil_fa_rate))\n",
    "    narrative_summary.close()\n",
    "    print(\"narrative_summary created successfully for %s\" %(subject))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptual Domain Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_all_group_older_desc_perceptual = pd.DataFrame(columns=['subject', 'target_hit', 'lure_cr','foil_cr'])\n",
    "\n",
    "for subject in sublist_older: \n",
    "    perceptual_summary = open(os.path.join(output_dir, f'sub-{subject}_group-older_task-recognition_desc-perceptual_results.txt'), 'w')\n",
    "    perceptual_summary.write('subject: %d\\n' %(subject))\n",
    "    perceptual_summary.write('performance_summary\\n\\n\\n\\nraw_data\\n\\n')\n",
    "    perceptual_summary.write('target,target_hit,target_miss,lure,lure_cr,lure_fa,foil,foil_cr,foil_fa,junk\\n')\n",
    "    \n",
    "    performance=[]\n",
    "    target=0\n",
    "    target_hit=0\n",
    "    target_miss=0\n",
    "    lure=0\n",
    "    lure_cr=0\n",
    "    lure_fa=0\n",
    "    foil=0\n",
    "    foil_cr=0\n",
    "    foil_fa=0\n",
    "    junk=0\n",
    "    \n",
    "    with open(os.path.join(data_dir, f'sub-{subject}_group-older_task-recognition_desc-perceptual.txt')) as fd:\n",
    "        for line in islice(csv.reader(fd), 5, None):\n",
    "            performance.append([line[0],line[1],line[2],line[3],line[4]])\n",
    "            if 't' in line[1]:\n",
    "                target+=1\n",
    "            if 't' in line[1] and line[3]=='t':\n",
    "                target_hit+=1\n",
    "            if 't' in line[1] and line[3]=='f':\n",
    "                target_miss+=1\n",
    "            # Start move to lure trials\n",
    "            if 's' in line[1]:\n",
    "                lure+=1\n",
    "            if 's' in line[1] and line[3]=='t':\n",
    "                lure_fa+=1\n",
    "            if 's' in line[1] and line[3]=='f':\n",
    "                lure_cr+=1\n",
    "            if 'd' in line[1]:\n",
    "                foil+=1\n",
    "            if 'd' in line[1] and line[3]=='t':\n",
    "                foil_fa+=1\n",
    "            if 'd' in line[1] and line[3]=='f':\n",
    "                foil_cr+=1\n",
    "            if line [1] == '':\n",
    "                junk+=1\n",
    "            \n",
    "    target_hit = target_hit\n",
    "    target_miss = target_miss\n",
    "    lure_cr = lure_cr\n",
    "    lure_fa = lure_fa\n",
    "    target_hit_rate = target_hit / (target)\n",
    "    fa_cr_rate = foil_cr / (foil)\n",
    "    target_miss_rate = target_miss/target\n",
    "    lure_cr_rate = lure_cr/lure\n",
    "    lure_fa_rate = lure_fa/lure\n",
    "    foil_cr_rate = foil_cr/foil\n",
    "    foil_fa_rate = foil_fa/foil\n",
    "    cr = lure_cr + foil_cr\n",
    "    cr_rate = (lure_cr + foil_cr)/(lure + foil)\n",
    "    fa = lure_fa + foil_fa\n",
    "    fa_rate = (lure_fa + foil_fa)/(lure + foil)\n",
    "    \n",
    "    if target_hit_rate == 1: \n",
    "        target_hit_rate = (target - 0.5) / (target)\n",
    "    if target_hit_rate == 0: \n",
    "        target_hit_rate = 0.5 / (target)\n",
    "        \n",
    "    if foil_fa_rate == 1: \n",
    "        foil_fa_rate = (foil - 0.5) / (foil)\n",
    "    if foil_fa_rate == 0: \n",
    "        foil_fa_rate = 0.5 / (foil)    \n",
    "    \n",
    "    dprime = Z(target_hit_rate) - Z(foil_fa_rate)\n",
    "    dprime_lures = Z(target_hit_rate) - Z(lure_fa_rate)\n",
    "    \n",
    "    LDI = lure_cr_rate - target_miss_rate\n",
    "    \n",
    "    beta = math.exp((Z(fa_rate)**2 - Z(target_hit_rate)**2) / 2)\n",
    "    c = -(Z(target_hit_rate) + Z(fa_rate)) / 2\n",
    "    ad = norm.cdf(dprime / math.sqrt(2))\n",
    "    \n",
    "    # Append our big data frame with each subject's data\n",
    "    \n",
    "    sub_all_group_older_desc_perceptual = sub_all_group_older_desc_perceptual.append(pd.DataFrame\\\n",
    "    ({'subject': subject, 'target_hit': target_hit, 'target_miss': target_miss,\\\n",
    "      'lure_cr': lure_cr, 'lure_fa': lure_fa,\\\n",
    "      'foil_cr': foil_cr, 'foil_fa':foil_fa,\\\n",
    "      'target_hit_rate': target_hit_rate, 'lure_cr_rate': lure_cr_rate,'foil_cr_rate': foil_cr_rate,\\\n",
    "      'lure_fa_rate': lure_fa_rate, 'foil_fa_rate':foil_fa_rate,\\\n",
    "      'cr': cr, 'cr_rate': cr_rate, 'fa': fa,'fa_rate': fa_rate,\\\n",
    "      'dprime':dprime, 'dprime_lures':dprime_lures, 'LDI':LDI, 'beta':beta, 'c':c, 'ad':ad}, index=[0]), ignore_index=True)\n",
    "\n",
    "    #Append performance summary file\n",
    "    perceptual_summary.write(\"%d,%d,%d,%d,%d,%d,%d,%d,%d,%d\\n\\n\\n\\n\" %(target,target_hit,target_miss,lure,lure_cr,lure_fa,foil,foil_cr,foil_fa,junk))\n",
    "    perceptual_summary.write(\"targets\\n\\ntarget_hit_rate,target_miss_rate\\n\")\n",
    "    perceptual_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(target_hit_rate,target_miss_rate))\n",
    "    perceptual_summary.write(\"lures\\n\\nlure_cr_rate,lure_fa_rate\\n\")\n",
    "    perceptual_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(lure_cr_rate,lure_fa_rate))\n",
    "    perceptual_summary.write(\"foils\\n\\nfoil_cr_rate,foil_fa_rate\\n\")\n",
    "    perceptual_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(foil_cr_rate,foil_fa_rate))\n",
    "    perceptual_summary.close()\n",
    "    print(\"perceptual_summary created successfully for %s\" %(subject))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Younger Adults "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sublist_younger = pd.read_csv(os.path.join(base_dir, 'code/sub-all_group-younger_desc-subject_list.txt'), header=None)\n",
    "sublist_younger = sublist_younger[0].values.tolist()\n",
    "sublist_younger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Narrative Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = norm.ppf\n",
    "\n",
    "sub_all_group_younger_desc_narrative = pd.DataFrame(columns=['subject', 'target_hit', 'lure_cr','foil_cr'])\n",
    "\n",
    "for subject in sublist_younger: \n",
    "    narrative_summary = open(os.path.join(output_dir, f'sub-{subject}_group-younger_task-recognition_desc-narrative_results.txt'), 'w')\n",
    "    narrative_summary.write('subject: %d\\n' %(subject))\n",
    "    narrative_summary.write('performance_summary\\n\\n\\n\\nraw_data\\n\\n')\n",
    "    narrative_summary.write('target,target_hit,target_miss,lure,lure_cr,lure_fa,foil,foil_cr,foil_fa,junk\\n')\n",
    "    \n",
    "    performance=[]\n",
    "    target=0\n",
    "    target_hit=0\n",
    "    target_miss=0\n",
    "    lure=0\n",
    "    lure_cr=0\n",
    "    lure_fa=0\n",
    "    foil=0\n",
    "    foil_cr=0\n",
    "    foil_fa=0\n",
    "    junk=0\n",
    "    \n",
    "    with open(os.path.join(data_dir, f'sub-{subject}_group-younger_task-recognition_desc-narrative.txt')) as fd:\n",
    "        for line in islice(csv.reader(fd), 5, None):\n",
    "            performance.append([line[0],line[1],line[2],line[3],line[4]])\n",
    "            if 't' in line[1]:\n",
    "                target+=1\n",
    "            if 't' in line[1] and line[3]=='t':\n",
    "                target_hit+=1\n",
    "            if 't' in line[1] and line[3]=='f':\n",
    "                target_miss+=1\n",
    "            # Start move to lure trials\n",
    "            if 's' in line[1]:\n",
    "                lure+=1\n",
    "            if 's' in line[1] and line[3]=='t':\n",
    "                lure_fa+=1\n",
    "            if 's' in line[1] and line[3]=='f':\n",
    "                lure_cr+=1\n",
    "            if 'n' in line[1]:\n",
    "                foil+=1\n",
    "            if 'n' in line[1] and line[3]=='t':\n",
    "                foil_fa+=1\n",
    "            if 'n' in line[1] and line[3]=='f':\n",
    "                foil_cr+=1\n",
    "            if line [1] == '':\n",
    "                junk+=1\n",
    "            \n",
    "    target_hit = target_hit\n",
    "    target_miss = target_miss\n",
    "    lure_cr = lure_cr\n",
    "    lure_fa = lure_fa\n",
    "    target_hit_rate = target_hit / (target)\n",
    "    fa_cr_rate = foil_cr / (foil)\n",
    "    target_miss_rate = target_miss/target\n",
    "    lure_cr_rate = lure_cr/lure\n",
    "    lure_fa_rate = lure_fa/lure\n",
    "    foil_cr_rate = foil_cr/foil\n",
    "    foil_fa_rate = foil_fa/foil\n",
    "    cr = lure_cr + foil_cr\n",
    "    cr_rate = (lure_cr + foil_cr)/(lure + foil)\n",
    "    fa = lure_fa + foil_fa\n",
    "    fa_rate = (lure_fa + foil_fa)/(lure + foil)\n",
    "    \n",
    "    if target_hit_rate == 1: \n",
    "        target_hit_rate = (target - 0.5) / (target)\n",
    "    if target_hit_rate == 0: \n",
    "        target_hit_rate = 0.5 / (target)\n",
    "        \n",
    "    if foil_fa_rate == 1: \n",
    "        foil_fa_rate = (foil - 0.5) / (foil)\n",
    "    if foil_fa_rate == 0: \n",
    "        foil_fa_rate = 0.5 / (foil)    \n",
    "    \n",
    "    dprime = Z(target_hit_rate) - Z(foil_fa_rate)\n",
    "    dprime_lures = Z(target_hit_rate) - Z(lure_fa_rate)\n",
    "    \n",
    "    LDI = lure_cr_rate - target_miss_rate\n",
    "    \n",
    "    beta = math.exp((Z(fa_rate)**2 - Z(target_hit_rate)**2) / 2)\n",
    "    c = -(Z(target_hit_rate) + Z(fa_rate)) / 2\n",
    "    ad = norm.cdf(dprime / math.sqrt(2))\n",
    "    \n",
    "    # Append our big data frame with each subject's data\n",
    "    \n",
    "    sub_all_group_younger_desc_narrative = sub_all_group_younger_desc_narrative.append(pd.DataFrame\\\n",
    "    ({'subject': subject, 'target_hit': target_hit, 'target_miss': target_miss,\\\n",
    "      'lure_cr': lure_cr, 'lure_fa': lure_fa,\\\n",
    "      'foil_cr': foil_cr, 'foil_fa':foil_fa,\\\n",
    "      'target_hit_rate': target_hit_rate, 'lure_cr_rate': lure_cr_rate,'foil_cr_rate': foil_cr_rate,\\\n",
    "      'lure_fa_rate': lure_fa_rate, 'foil_fa_rate':foil_fa_rate,\\\n",
    "      'cr': cr, 'cr_rate': cr_rate, 'fa': fa,'fa_rate': fa_rate,\\\n",
    "      'dprime':dprime, 'dprime_lures':dprime_lures, 'LDI':LDI, 'beta':beta, 'c':c, 'ad':ad}, index=[0]), ignore_index=True)\n",
    "\n",
    "    #Append performance summary file\n",
    "#     narrative_summary.write(\"%d,%d,%d,%d,%d,%d,%d,%d,%d,%d\\n\\n\\n\\n\" %(target,target_hit,target_miss,lure,lure_cr,lure_fa,foil,foil_cr,foil_fa,junk))\n",
    "#     narrative_summary.write(\"targets\\n\\ntarget_hit_rate,target_miss_rate\\n\")\n",
    "#     narrative_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(target_hit_rate,target_miss_rate))\n",
    "#     narrative_summary.write(\"lures\\n\\nlure_cr_rate,lure_fa_rate\\n\")\n",
    "#     narrative_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(lure_cr_rate,lure_fa_rate))\n",
    "#     narrative_summary.write(\"foils\\n\\nfoil_cr_rate,foil_fa_rate\\n\")\n",
    "#     narrative_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(foil_cr_rate,foil_fa_rate))\n",
    "#     narrative_summary.close()\n",
    "#     print(\"narrative_summary created successfully for %s\" %(subject))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_all_group_younger_desc_perceptual = pd.DataFrame(columns=['subject', 'target_hit', 'lure_cr','foil_cr'])\n",
    "\n",
    "for subject in sublist_younger: \n",
    "    perceptual_summary = open(os.path.join(output_dir, f'sub-{subject}_group-younger_task-recognition_desc-perceptual_results.txt'), 'w')\n",
    "    perceptual_summary.write('subject: %d\\n' %(subject))\n",
    "    perceptual_summary.write('performance_summary\\n\\n\\n\\nraw_data\\n\\n')\n",
    "    perceptual_summary.write('target,target_hit,target_miss,lure,lure_cr,lure_fa,foil,foil_cr,foil_fa,junk\\n')\n",
    "    \n",
    "    performance=[]\n",
    "    target=0\n",
    "    target_hit=0\n",
    "    target_miss=0\n",
    "    lure=0\n",
    "    lure_cr=0\n",
    "    lure_fa=0\n",
    "    foil=0\n",
    "    foil_cr=0\n",
    "    foil_fa=0\n",
    "    junk=0\n",
    "    \n",
    "    with open(os.path.join(data_dir, f'sub-{subject}_group-younger_task-recognition_desc-perceptual.txt')) as fd:\n",
    "        for line in islice(csv.reader(fd), 5, None):\n",
    "            performance.append([line[0],line[1],line[2],line[3],line[4]])\n",
    "            if 't' in line[1]:\n",
    "                target+=1\n",
    "            if 't' in line[1] and line[3]=='t':\n",
    "                target_hit+=1\n",
    "            if 't' in line[1] and line[3]=='f':\n",
    "                target_miss+=1\n",
    "            # Start move to lure trials\n",
    "            if 's' in line[1]:\n",
    "                lure+=1\n",
    "            if 's' in line[1] and line[3]=='t':\n",
    "                lure_fa+=1\n",
    "            if 's' in line[1] and line[3]=='f':\n",
    "                lure_cr+=1\n",
    "            if 'd' in line[1]:\n",
    "                foil+=1\n",
    "            if 'd' in line[1] and line[3]=='t':\n",
    "                foil_fa+=1\n",
    "            if 'd' in line[1] and line[3]=='f':\n",
    "                foil_cr+=1\n",
    "            if line [1] == '':\n",
    "                junk+=1\n",
    "            \n",
    "    target_hit = target_hit\n",
    "    target_miss = target_miss\n",
    "    lure_cr = lure_cr\n",
    "    lure_fa = lure_fa\n",
    "    target_hit_rate = target_hit / (target)\n",
    "    fa_cr_rate = foil_cr / (foil)\n",
    "    target_miss_rate = target_miss/target\n",
    "    lure_cr_rate = lure_cr/lure\n",
    "    lure_fa_rate = lure_fa/lure\n",
    "    foil_cr_rate = foil_cr/foil\n",
    "    foil_fa_rate = foil_fa/foil\n",
    "    cr = lure_cr + foil_cr\n",
    "    cr_rate = (lure_cr + foil_cr)/(lure + foil)\n",
    "    fa = lure_fa + foil_fa\n",
    "    fa_rate = (lure_fa + foil_fa)/(lure + foil)\n",
    "    \n",
    "    if target_hit_rate == 1: \n",
    "        target_hit_rate = (target - 0.5) / (target)\n",
    "    if target_hit_rate == 0: \n",
    "        target_hit_rate = 0.5 / (target)\n",
    "        \n",
    "    if foil_fa_rate == 1: \n",
    "        foil_fa_rate = (foil - 0.5) / (foil)\n",
    "    if foil_fa_rate == 0: \n",
    "        foil_fa_rate = 0.5 / (foil)    \n",
    "    \n",
    "    dprime = Z(target_hit_rate) - Z(foil_fa_rate)\n",
    "    dprime_lures = Z(target_hit_rate) - Z(lure_fa_rate)\n",
    "    \n",
    "    LDI = lure_cr_rate - target_miss_rate\n",
    "    \n",
    "    beta = math.exp((Z(fa_rate)**2 - Z(target_hit_rate)**2) / 2)\n",
    "    c = -(Z(target_hit_rate) + Z(fa_rate)) / 2\n",
    "    ad = norm.cdf(dprime / math.sqrt(2))\n",
    "    \n",
    "    # Append our big data frame with each subject's data\n",
    "    \n",
    "    sub_all_group_younger_desc_perceptual = sub_all_group_younger_desc_perceptual.append(pd.DataFrame\\\n",
    "    ({'subject': subject, 'target_hit': target_hit, 'target_miss': target_miss,\\\n",
    "      'lure_cr': lure_cr, 'lure_fa': lure_fa,\\\n",
    "      'foil_cr': foil_cr, 'foil_fa':foil_fa,\\\n",
    "      'target_hit_rate': target_hit_rate, 'lure_cr_rate': lure_cr_rate,'foil_cr_rate': foil_cr_rate,\\\n",
    "      'lure_fa_rate': lure_fa_rate, 'foil_fa_rate':foil_fa_rate,\\\n",
    "      'cr': cr, 'cr_rate': cr_rate, 'fa': fa,'fa_rate': fa_rate,\\\n",
    "      'dprime':dprime, 'dprime_lures':dprime_lures, 'LDI':LDI, 'beta':beta, 'c':c, 'ad':ad}, index=[0]), ignore_index=True)\n",
    "\n",
    "    #Append performance summary file\n",
    "#     perceptual_summary.write(\"%d,%d,%d,%d,%d,%d,%d,%d,%d,%d\\n\\n\\n\\n\" %(target,target_hit,target_miss,lure,lure_cr,lure_fa,foil,foil_cr,foil_fa,junk))\n",
    "#     perceptual_summary.write(\"targets\\n\\ntarget_hit_rate,target_miss_rate\\n\")\n",
    "#     perceptual_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(target_hit_rate,target_miss_rate))\n",
    "#     perceptual_summary.write(\"lures\\n\\nlure_cr_rate,lure_fa_rate\\n\")\n",
    "#     perceptual_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(lure_cr_rate,lure_fa_rate))\n",
    "#     perceptual_summary.write(\"foils\\n\\nfoil_cr_rate,foil_fa_rate\\n\")\n",
    "#     perceptual_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(foil_cr_rate,foil_fa_rate))\n",
    "#     perceptual_summary.close()\n",
    "#     print(\"perceptual_summary created successfully for %s\" %(subject))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append Older and Younger Adults' Output files together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>target_hit</th>\n",
       "      <th>lure_cr</th>\n",
       "      <th>foil_cr</th>\n",
       "      <th>target_miss</th>\n",
       "      <th>lure_fa</th>\n",
       "      <th>foil_fa</th>\n",
       "      <th>target_hit_rate</th>\n",
       "      <th>lure_cr_rate</th>\n",
       "      <th>foil_cr_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>fa</th>\n",
       "      <th>fa_rate</th>\n",
       "      <th>dprime</th>\n",
       "      <th>dprime_lures</th>\n",
       "      <th>LDI</th>\n",
       "      <th>beta</th>\n",
       "      <th>c</th>\n",
       "      <th>ad</th>\n",
       "      <th>group</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>3.409597</td>\n",
       "      <td>2.392323</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>1.357225</td>\n",
       "      <td>0.109767</td>\n",
       "      <td>0.992044</td>\n",
       "      <td>older</td>\n",
       "      <td>narrative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3.961960</td>\n",
       "      <td>2.264642</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.297105</td>\n",
       "      <td>-0.433247</td>\n",
       "      <td>0.997457</td>\n",
       "      <td>older</td>\n",
       "      <td>narrative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>203</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>2.675536</td>\n",
       "      <td>1.569535</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.300493</td>\n",
       "      <td>0.134575</td>\n",
       "      <td>0.970747</td>\n",
       "      <td>older</td>\n",
       "      <td>narrative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>2.652446</td>\n",
       "      <td>1.635172</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>2.688898</td>\n",
       "      <td>0.488343</td>\n",
       "      <td>0.969642</td>\n",
       "      <td>older</td>\n",
       "      <td>narrative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>2.801336</td>\n",
       "      <td>1.695335</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.160620</td>\n",
       "      <td>0.071675</td>\n",
       "      <td>0.976196</td>\n",
       "      <td>older</td>\n",
       "      <td>narrative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>317</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.961960</td>\n",
       "      <td>2.087262</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.265150</td>\n",
       "      <td>-0.496147</td>\n",
       "      <td>0.997457</td>\n",
       "      <td>younger</td>\n",
       "      <td>perceptual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>318</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.629131</td>\n",
       "      <td>2.342707</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.736797</td>\n",
       "      <td>-0.109767</td>\n",
       "      <td>0.994859</td>\n",
       "      <td>younger</td>\n",
       "      <td>perceptual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>319</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>4.256090</td>\n",
       "      <td>3.629131</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.558407</td>\n",
       "      <td>-0.147065</td>\n",
       "      <td>0.998692</td>\n",
       "      <td>younger</td>\n",
       "      <td>perceptual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>320</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>3.629131</td>\n",
       "      <td>3.002172</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.741927</td>\n",
       "      <td>0.166414</td>\n",
       "      <td>0.994859</td>\n",
       "      <td>younger</td>\n",
       "      <td>perceptual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>321</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3.961960</td>\n",
       "      <td>2.264642</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.297105</td>\n",
       "      <td>-0.433247</td>\n",
       "      <td>0.997457</td>\n",
       "      <td>younger</td>\n",
       "      <td>perceptual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject target_hit lure_cr foil_cr  target_miss  lure_fa  foil_fa  \\\n",
       "0      201         27      26      30          3.0      4.0      0.0   \n",
       "1      202         29      20      30          1.0     10.0      0.0   \n",
       "2      203         24      23      29          6.0      7.0      1.0   \n",
       "3      204         21      26      30          9.0      4.0      0.0   \n",
       "4      205         25      23      29          5.0      7.0      1.0   \n",
       "..     ...        ...     ...     ...          ...      ...      ...   \n",
       "16     317         29      18      30          1.0     12.0      0.0   \n",
       "17     318         28      24      30          2.0      6.0      0.0   \n",
       "18     319         30      28      30          0.0      2.0      0.0   \n",
       "19     320         28      28      30          2.0      2.0      0.0   \n",
       "20     321         29      20      30          1.0     10.0      0.0   \n",
       "\n",
       "    target_hit_rate  lure_cr_rate  foil_cr_rate  ...    fa   fa_rate  \\\n",
       "0          0.900000      0.866667      1.000000  ...   4.0  0.066667   \n",
       "1          0.966667      0.666667      1.000000  ...  10.0  0.166667   \n",
       "2          0.800000      0.766667      0.966667  ...   8.0  0.133333   \n",
       "3          0.700000      0.866667      1.000000  ...   4.0  0.066667   \n",
       "4          0.833333      0.766667      0.966667  ...   8.0  0.133333   \n",
       "..              ...           ...           ...  ...   ...       ...   \n",
       "16         0.966667      0.600000      1.000000  ...  12.0  0.200000   \n",
       "17         0.933333      0.800000      1.000000  ...   6.0  0.100000   \n",
       "18         0.983333      0.933333      1.000000  ...   2.0  0.033333   \n",
       "19         0.933333      0.933333      1.000000  ...   2.0  0.033333   \n",
       "20         0.966667      0.666667      1.000000  ...  10.0  0.166667   \n",
       "\n",
       "      dprime  dprime_lures       LDI      beta         c        ad    group  \\\n",
       "0   3.409597      2.392323  0.766667  1.357225  0.109767  0.992044    older   \n",
       "1   3.961960      2.264642  0.633333  0.297105 -0.433247  0.997457    older   \n",
       "2   2.675536      1.569535  0.566667  1.300493  0.134575  0.970747    older   \n",
       "3   2.652446      1.635172  0.566667  2.688898  0.488343  0.969642    older   \n",
       "4   2.801336      1.695335  0.600000  1.160620  0.071675  0.976196    older   \n",
       "..       ...           ...       ...       ...       ...       ...      ...   \n",
       "16  3.961960      2.087262  0.566667  0.265150 -0.496147  0.997457  younger   \n",
       "17  3.629131      2.342707  0.733333  0.736797 -0.109767  0.994859  younger   \n",
       "18  4.256090      3.629131  0.933333  0.558407 -0.147065  0.998692  younger   \n",
       "19  3.629131      3.002172  0.866667  1.741927  0.166414  0.994859  younger   \n",
       "20  3.961960      2.264642  0.633333  0.297105 -0.433247  0.997457  younger   \n",
       "\n",
       "          type  \n",
       "0    narrative  \n",
       "1    narrative  \n",
       "2    narrative  \n",
       "3    narrative  \n",
       "4    narrative  \n",
       "..         ...  \n",
       "16  perceptual  \n",
       "17  perceptual  \n",
       "18  perceptual  \n",
       "19  perceptual  \n",
       "20  perceptual  \n",
       "\n",
       "[84 rows x 24 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_all_group_older_desc_narrative[\"group\"] = \"older\"\n",
    "sub_all_group_older_desc_perceptual[\"group\"] = \"older\"\n",
    "sub_all_group_younger_desc_narrative[\"group\"] = \"younger\"\n",
    "sub_all_group_younger_desc_perceptual[\"group\"] = \"younger\"\n",
    "\n",
    "sub_all_group_older_desc_narrative[\"type\"] = \"narrative\"\n",
    "sub_all_group_older_desc_perceptual[\"type\"] = \"perceptual\"\n",
    "sub_all_group_younger_desc_narrative[\"type\"] = \"narrative\"\n",
    "sub_all_group_younger_desc_perceptual[\"type\"] = \"perceptual\"\n",
    "\n",
    "sub_all_group_all_desc_narrative = pd.concat([sub_all_group_older_desc_narrative, sub_all_group_younger_desc_narrative])\n",
    "sub_all_group_all_desc_perceptual = pd.concat([sub_all_group_older_desc_perceptual, sub_all_group_younger_desc_perceptual])\n",
    "\n",
    "sub_all_group_older = pd.concat([sub_all_group_older_desc_narrative, sub_all_group_older_desc_perceptual])\n",
    "sub_all_group_younger = pd.concat([sub_all_group_younger_desc_narrative, sub_all_group_younger_desc_perceptual])\n",
    "\n",
    "sub_all_group_all_desc_all = pd.concat([sub_all_group_all_desc_narrative, sub_all_group_all_desc_perceptual])\n",
    "sub_all_group_all_desc_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add neuropsychological test results on exisiting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuropsych = pd.read_csv(os.path.join(base_dir, 'data/neuropsych/neuropsych_scores.csv'))\n",
    "#neuropsych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_all_group_older = pd.merge(sub_all_group_older, neuropsych, left_on='subject', right_on='subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_all_group_all_desc_recog_neuropsych = pd.concat([sub_all_group_older, sub_all_group_younger])\n",
    "#sub_all_group_all_desc_recog_neuropsych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_all_group_all_desc_recog_neuropsych[\"group_type\"] = sub_all_group_all_desc_recog_neuropsych[\"group\"] + \"_\" +sub_all_group_all_desc_recog_neuropsych[\"type\"]\n",
    "#sub_all_group_all_desc_recog_neuropsych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export appended dataframe to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_all_group_younger_desc_narrative.to_csv(os.path.join(output_dir, f'sub-all_group-younger_task-recognition_desc-narrative_results.csv'), index = None, header=True)\n",
    "# sub_all_group_younger_desc_perceptual.to_csv(os.path.join(output_dir, f'sub-all_group-younger_task-recognition_desc-perceptual_results.csv'), index = None, header=True)\n",
    "# sub_all_group_older_desc_narrative.to_csv(os.path.join(output_dir, f'sub-all_group-older_task-recognition_desc-narrative_results.csv'), index = None, header=True)\n",
    "# sub_all_group_older_desc_perceptual.to_csv(os.path.join(output_dir, f'sub-all_group-older_task-recognition_desc-perceptual_results.csv'), index = None, header=True)\n",
    "# sub_all_group_all_desc_narrative.to_csv(os.path.join(output_dir, f'sub-all_group-all_task-recognition_desc-narrative_results.csv'), index = None, header=True)\n",
    "# sub_all_group_all_desc_perceptual.to_csv(os.path.join(output_dir, f'sub-all_group-all_task-recognition_desc-perceptual_results.csv'), index = None, header=True)\n",
    "# sub_all_group_all_desc_all.to_csv(os.path.join(output_dir, f'sub-all_group-all_task-recognition_desc-all_results.csv'), index = None, header=True)\n",
    "# sub_all_group_all_desc_recog_neuropsych.to_csv(os.path.join(output_dir, f'sub-all_group-all_task-recognition_desc-all_results_neuropsych.csv'), index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
