{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curbage Recognition Experiment Set Up\n",
    "### Zachariah M. Reagh & Angelique I. Delarazan\n",
    "#### 12/01/2022\n",
    "Edited: Changed LDI formula from p(New|Lure) - p(New|Target) to p(New|Lure) - p(Old|Foil) to fit reviewer suggestion \n",
    "\n",
    "Generates csv files: \n",
    "1. Calculates hits, misses, false, alarms, and correct rejects for each subject for each domain type (Narrative v. Perceptual)\n",
    "2. Output csv files based on group (Younger v. Older Adults)\n",
    "3. Appends groups and outpust csv files for further analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from itertools import islice\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Volumes/GAMMA/curbage_behavioral/experiment1/'\n",
    "data_dir = os.path.join(base_dir, f'data/recognition/')\n",
    "output_dir = '/Volumes/GAMMA/curbage_recognition/reviews/analyses/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate hits, misses, false alarms, and correct rejections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Older Adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in older adults' individual data and create a list\n",
    "sublist_older = pd.read_csv(os.path.join(base_dir, 'code/sub-all_group-older_desc-subject_list.txt'), header=None)\n",
    "sublist_older = sublist_older[0].values.tolist()\n",
    "sublist_older"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Narrative Domain Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "narrative_summary created successfully for 201\n",
      "narrative_summary created successfully for 202\n",
      "narrative_summary created successfully for 203\n",
      "narrative_summary created successfully for 204\n",
      "narrative_summary created successfully for 205\n",
      "narrative_summary created successfully for 206\n",
      "narrative_summary created successfully for 207\n",
      "narrative_summary created successfully for 208\n",
      "narrative_summary created successfully for 209\n",
      "narrative_summary created successfully for 210\n",
      "narrative_summary created successfully for 211\n",
      "narrative_summary created successfully for 212\n",
      "narrative_summary created successfully for 213\n",
      "narrative_summary created successfully for 214\n",
      "narrative_summary created successfully for 215\n",
      "narrative_summary created successfully for 216\n",
      "narrative_summary created successfully for 217\n",
      "narrative_summary created successfully for 218\n",
      "narrative_summary created successfully for 219\n",
      "narrative_summary created successfully for 220\n",
      "narrative_summary created successfully for 221\n"
     ]
    }
   ],
   "source": [
    "# Loop through all subjects on list and create output file, calculating subject's performance for the Narrative Task\n",
    "Z = norm.ppf\n",
    "\n",
    "sub_all_group_older_desc_narrative = pd.DataFrame(columns=['subject', 'target_hit', 'lure_cr','foil_cr'])\n",
    "\n",
    "for subject in sublist_older: \n",
    "    narrative_summary = open(os.path.join(output_dir, f'sub-{subject}_group-older_task-recognition_desc-narrative_results.txt'), 'w')\n",
    "    narrative_summary.write('subject: %d\\n' %(subject))\n",
    "    narrative_summary.write('performance_summary\\n\\n\\n\\nraw_data\\n\\n')\n",
    "    narrative_summary.write('target,target_hit,target_miss,lure,lure_cr,lure_fa,foil,foil_cr,foil_fa,junk\\n')\n",
    "    \n",
    "    performance=[]\n",
    "    target=0\n",
    "    target_hit=0\n",
    "    target_miss=0\n",
    "    lure=0\n",
    "    lure_cr=0\n",
    "    lure_fa=0\n",
    "    foil=0\n",
    "    foil_cr=0\n",
    "    foil_fa=0\n",
    "    junk=0\n",
    "    \n",
    "    with open(os.path.join(data_dir, f'sub-{subject}_group-older_task-recognition_desc-narrative.txt')) as fd:\n",
    "        for line in islice(csv.reader(fd), 5, None):\n",
    "            performance.append([line[0],line[1],line[2],line[3],line[4]])\n",
    "            if 't' in line[1]:\n",
    "                target+=1\n",
    "            if 't' in line[1] and line[3]=='t':\n",
    "                target_hit+=1\n",
    "            if 't' in line[1] and line[3]=='f':\n",
    "                target_miss+=1\n",
    "            # Start move to lure trials\n",
    "            if 's' in line[1]:\n",
    "                lure+=1\n",
    "            if 's' in line[1] and line[3]=='t':\n",
    "                lure_fa+=1\n",
    "            if 's' in line[1] and line[3]=='f':\n",
    "                lure_cr+=1\n",
    "            if 'n' in line[1]:\n",
    "                foil+=1\n",
    "            if 'n' in line[1] and line[3]=='t':\n",
    "                foil_fa+=1\n",
    "            if 'n' in line[1] and line[3]=='f':\n",
    "                foil_cr+=1\n",
    "            if line [1] == '':\n",
    "                junk+=1\n",
    "            \n",
    "    target_hit = target_hit\n",
    "    target_miss = target_miss\n",
    "    lure_cr = lure_cr\n",
    "    lure_fa = lure_fa\n",
    "    target_hit_rate = target_hit / (target)\n",
    "    fa_cr_rate = foil_cr / (foil)\n",
    "    target_miss_rate = target_miss/target\n",
    "    lure_cr_rate = lure_cr/lure\n",
    "    lure_fa_rate = lure_fa/lure\n",
    "    foil_cr_rate = foil_cr/foil\n",
    "    foil_fa_rate = foil_fa/foil\n",
    "    cr = lure_cr + foil_cr\n",
    "    cr_rate = (lure_cr + foil_cr)/(lure + foil)\n",
    "    fa = lure_fa + foil_fa\n",
    "    fa_rate = (lure_fa + foil_fa)/(lure + foil)\n",
    "    \n",
    "    if target_hit_rate == 1: \n",
    "        target_hit_rate = (target - 0.5) / (target)\n",
    "    if target_hit_rate == 0: \n",
    "        target_hit_rate = 0.5 / (target)\n",
    "        \n",
    "    if foil_fa_rate == 1: \n",
    "        foil_fa_rate = (foil - 0.5) / (foil)\n",
    "    if foil_fa_rate == 0: \n",
    "        foil_fa_rate = 0.5 / (foil)    \n",
    "    \n",
    "    dprime = Z(target_hit_rate) - Z(foil_fa_rate)\n",
    "    dprime_lures = Z(target_hit_rate) - Z(lure_fa_rate)\n",
    "    \n",
    "    LDI = lure_cr_rate - target_miss_rate\n",
    "    \n",
    "    LDI_reviewer = lure_cr_rate - foil_fa_rate\n",
    "    \n",
    "    beta = math.exp((Z(fa_rate)**2 - Z(target_hit_rate)**2) / 2)\n",
    "    c = -(Z(target_hit_rate) + Z(fa_rate)) / 2\n",
    "    ad = norm.cdf(dprime / math.sqrt(2))\n",
    "    \n",
    "    # Append our big data frame with each subject's data\n",
    "    \n",
    "    sub_all_group_older_desc_narrative = sub_all_group_older_desc_narrative.append(pd.DataFrame\\\n",
    "    ({'subject': subject, 'target_hit': target_hit, 'target_miss': target_miss,\\\n",
    "      'lure_cr': lure_cr, 'lure_fa': lure_fa,\\\n",
    "      'foil_cr': foil_cr, 'foil_fa':foil_fa,\\\n",
    "      'target_hit_rate': target_hit_rate, 'lure_cr_rate': lure_cr_rate,'foil_cr_rate': foil_cr_rate,\\\n",
    "      'lure_fa_rate': lure_fa_rate, 'foil_fa_rate':foil_fa_rate,\\\n",
    "      'cr': cr, 'cr_rate': cr_rate, 'fa': fa,'fa_rate': fa_rate,\\\n",
    "      'dprime':dprime, 'dprime_lures':dprime_lures, 'LDI':LDI, 'LDI_reviewer':LDI_reviewer, 'beta':beta, 'c':c, 'ad':ad}, index=[0]), ignore_index=True)\n",
    "\n",
    "    #Append performance summary file\n",
    "    narrative_summary.write(\"%d,%d,%d,%d,%d,%d,%d,%d,%d,%d\\n\\n\\n\\n\" %(target,target_hit,target_miss,lure,lure_cr,lure_fa,foil,foil_cr,foil_fa,junk))\n",
    "    narrative_summary.write(\"targets\\n\\ntarget_hit_rate,target_miss_rate\\n\")\n",
    "    narrative_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(target_hit_rate,target_miss_rate))\n",
    "    narrative_summary.write(\"lures\\n\\nlure_cr_rate,lure_fa_rate\\n\")\n",
    "    narrative_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(lure_cr_rate,lure_fa_rate))\n",
    "    narrative_summary.write(\"foils\\n\\nfoil_cr_rate,foil_fa_rate\\n\")\n",
    "    narrative_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(foil_cr_rate,foil_fa_rate))\n",
    "    narrative_summary.close()\n",
    "    print(\"narrative_summary created successfully for %s\" %(subject))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptual Domain Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perceptual_summary created successfully for 201\n",
      "perceptual_summary created successfully for 202\n",
      "perceptual_summary created successfully for 203\n",
      "perceptual_summary created successfully for 204\n",
      "perceptual_summary created successfully for 205\n",
      "perceptual_summary created successfully for 206\n",
      "perceptual_summary created successfully for 207\n",
      "perceptual_summary created successfully for 208\n",
      "perceptual_summary created successfully for 209\n",
      "perceptual_summary created successfully for 210\n",
      "perceptual_summary created successfully for 211\n",
      "perceptual_summary created successfully for 212\n",
      "perceptual_summary created successfully for 213\n",
      "perceptual_summary created successfully for 214\n",
      "perceptual_summary created successfully for 215\n",
      "perceptual_summary created successfully for 216\n",
      "perceptual_summary created successfully for 217\n",
      "perceptual_summary created successfully for 218\n",
      "perceptual_summary created successfully for 219\n",
      "perceptual_summary created successfully for 220\n",
      "perceptual_summary created successfully for 221\n"
     ]
    }
   ],
   "source": [
    "sub_all_group_older_desc_perceptual = pd.DataFrame(columns=['subject', 'target_hit', 'lure_cr','foil_cr'])\n",
    "\n",
    "for subject in sublist_older: \n",
    "    perceptual_summary = open(os.path.join(output_dir, f'sub-{subject}_group-older_task-recognition_desc-perceptual_results.txt'), 'w')\n",
    "    perceptual_summary.write('subject: %d\\n' %(subject))\n",
    "    perceptual_summary.write('performance_summary\\n\\n\\n\\nraw_data\\n\\n')\n",
    "    perceptual_summary.write('target,target_hit,target_miss,lure,lure_cr,lure_fa,foil,foil_cr,foil_fa,junk\\n')\n",
    "    \n",
    "    performance=[]\n",
    "    target=0\n",
    "    target_hit=0\n",
    "    target_miss=0\n",
    "    lure=0\n",
    "    lure_cr=0\n",
    "    lure_fa=0\n",
    "    foil=0\n",
    "    foil_cr=0\n",
    "    foil_fa=0\n",
    "    junk=0\n",
    "    \n",
    "    with open(os.path.join(data_dir, f'sub-{subject}_group-older_task-recognition_desc-perceptual.txt')) as fd:\n",
    "        for line in islice(csv.reader(fd), 5, None):\n",
    "            performance.append([line[0],line[1],line[2],line[3],line[4]])\n",
    "            if 't' in line[1]:\n",
    "                target+=1\n",
    "            if 't' in line[1] and line[3]=='t':\n",
    "                target_hit+=1\n",
    "            if 't' in line[1] and line[3]=='f':\n",
    "                target_miss+=1\n",
    "            # Start move to lure trials\n",
    "            if 's' in line[1]:\n",
    "                lure+=1\n",
    "            if 's' in line[1] and line[3]=='t':\n",
    "                lure_fa+=1\n",
    "            if 's' in line[1] and line[3]=='f':\n",
    "                lure_cr+=1\n",
    "            if 'd' in line[1]:\n",
    "                foil+=1\n",
    "            if 'd' in line[1] and line[3]=='t':\n",
    "                foil_fa+=1\n",
    "            if 'd' in line[1] and line[3]=='f':\n",
    "                foil_cr+=1\n",
    "            if line [1] == '':\n",
    "                junk+=1\n",
    "            \n",
    "    target_hit = target_hit\n",
    "    target_miss = target_miss\n",
    "    lure_cr = lure_cr\n",
    "    lure_fa = lure_fa\n",
    "    target_hit_rate = target_hit / (target)\n",
    "    fa_cr_rate = foil_cr / (foil)\n",
    "    target_miss_rate = target_miss/target\n",
    "    lure_cr_rate = lure_cr/lure\n",
    "    lure_fa_rate = lure_fa/lure\n",
    "    foil_cr_rate = foil_cr/foil\n",
    "    foil_fa_rate = foil_fa/foil\n",
    "    cr = lure_cr + foil_cr\n",
    "    cr_rate = (lure_cr + foil_cr)/(lure + foil)\n",
    "    fa = lure_fa + foil_fa\n",
    "    fa_rate = (lure_fa + foil_fa)/(lure + foil)\n",
    "    \n",
    "    if target_hit_rate == 1: \n",
    "        target_hit_rate = (target - 0.5) / (target)\n",
    "    if target_hit_rate == 0: \n",
    "        target_hit_rate = 0.5 / (target)\n",
    "        \n",
    "    if foil_fa_rate == 1: \n",
    "        foil_fa_rate = (foil - 0.5) / (foil)\n",
    "    if foil_fa_rate == 0: \n",
    "        foil_fa_rate = 0.5 / (foil)    \n",
    "    \n",
    "    dprime = Z(target_hit_rate) - Z(foil_fa_rate)\n",
    "    dprime_lures = Z(target_hit_rate) - Z(lure_fa_rate)\n",
    "    \n",
    "    LDI = lure_cr_rate - target_miss_rate\n",
    "    \n",
    "    LDI_reviewer = lure_cr_rate - foil_fa_rate\n",
    "    \n",
    "    beta = math.exp((Z(fa_rate)**2 - Z(target_hit_rate)**2) / 2)\n",
    "    c = -(Z(target_hit_rate) + Z(fa_rate)) / 2\n",
    "    ad = norm.cdf(dprime / math.sqrt(2))\n",
    "    \n",
    "    # Append our big data frame with each subject's data\n",
    "    \n",
    "    sub_all_group_older_desc_perceptual = sub_all_group_older_desc_perceptual.append(pd.DataFrame\\\n",
    "    ({'subject': subject, 'target_hit': target_hit, 'target_miss': target_miss,\\\n",
    "      'lure_cr': lure_cr, 'lure_fa': lure_fa,\\\n",
    "      'foil_cr': foil_cr, 'foil_fa':foil_fa,\\\n",
    "      'target_hit_rate': target_hit_rate, 'lure_cr_rate': lure_cr_rate,'foil_cr_rate': foil_cr_rate,\\\n",
    "      'lure_fa_rate': lure_fa_rate, 'foil_fa_rate':foil_fa_rate,\\\n",
    "      'cr': cr, 'cr_rate': cr_rate, 'fa': fa,'fa_rate': fa_rate,\\\n",
    "      'dprime':dprime, 'dprime_lures':dprime_lures, 'LDI':LDI, 'LDI_reviewer':LDI_reviewer, 'beta':beta, 'c':c, 'ad':ad}, index=[0]), ignore_index=True)\n",
    "\n",
    "    #Append performance summary file\n",
    "    perceptual_summary.write(\"%d,%d,%d,%d,%d,%d,%d,%d,%d,%d\\n\\n\\n\\n\" %(target,target_hit,target_miss,lure,lure_cr,lure_fa,foil,foil_cr,foil_fa,junk))\n",
    "    perceptual_summary.write(\"targets\\n\\ntarget_hit_rate,target_miss_rate\\n\")\n",
    "    perceptual_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(target_hit_rate,target_miss_rate))\n",
    "    perceptual_summary.write(\"lures\\n\\nlure_cr_rate,lure_fa_rate\\n\")\n",
    "    perceptual_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(lure_cr_rate,lure_fa_rate))\n",
    "    perceptual_summary.write(\"foils\\n\\nfoil_cr_rate,foil_fa_rate\\n\")\n",
    "    perceptual_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(foil_cr_rate,foil_fa_rate))\n",
    "    perceptual_summary.close()\n",
    "    print(\"perceptual_summary created successfully for %s\" %(subject))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Younger Adults "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sublist_younger = pd.read_csv(os.path.join(base_dir, 'code/sub-all_group-younger_desc-subject_list.txt'), header=None)\n",
    "sublist_younger = sublist_younger[0].values.tolist()\n",
    "sublist_younger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Narrative Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "narrative_summary created successfully for 301\n",
      "narrative_summary created successfully for 302\n",
      "narrative_summary created successfully for 303\n",
      "narrative_summary created successfully for 304\n",
      "narrative_summary created successfully for 305\n",
      "narrative_summary created successfully for 306\n",
      "narrative_summary created successfully for 307\n",
      "narrative_summary created successfully for 308\n",
      "narrative_summary created successfully for 309\n",
      "narrative_summary created successfully for 310\n",
      "narrative_summary created successfully for 311\n",
      "narrative_summary created successfully for 312\n",
      "narrative_summary created successfully for 313\n",
      "narrative_summary created successfully for 314\n",
      "narrative_summary created successfully for 315\n",
      "narrative_summary created successfully for 316\n",
      "narrative_summary created successfully for 317\n",
      "narrative_summary created successfully for 318\n",
      "narrative_summary created successfully for 319\n",
      "narrative_summary created successfully for 320\n",
      "narrative_summary created successfully for 321\n"
     ]
    }
   ],
   "source": [
    "Z = norm.ppf\n",
    "\n",
    "sub_all_group_younger_desc_narrative = pd.DataFrame(columns=['subject', 'target_hit', 'lure_cr','foil_cr'])\n",
    "\n",
    "for subject in sublist_younger: \n",
    "    narrative_summary = open(os.path.join(output_dir, f'sub-{subject}_group-younger_task-recognition_desc-narrative_results.txt'), 'w')\n",
    "    narrative_summary.write('subject: %d\\n' %(subject))\n",
    "    narrative_summary.write('performance_summary\\n\\n\\n\\nraw_data\\n\\n')\n",
    "    narrative_summary.write('target,target_hit,target_miss,lure,lure_cr,lure_fa,foil,foil_cr,foil_fa,junk\\n')\n",
    "    \n",
    "    performance=[]\n",
    "    target=0\n",
    "    target_hit=0\n",
    "    target_miss=0\n",
    "    lure=0\n",
    "    lure_cr=0\n",
    "    lure_fa=0\n",
    "    foil=0\n",
    "    foil_cr=0\n",
    "    foil_fa=0\n",
    "    junk=0\n",
    "    \n",
    "    with open(os.path.join(data_dir, f'sub-{subject}_group-younger_task-recognition_desc-narrative.txt')) as fd:\n",
    "        for line in islice(csv.reader(fd), 5, None):\n",
    "            performance.append([line[0],line[1],line[2],line[3],line[4]])\n",
    "            if 't' in line[1]:\n",
    "                target+=1\n",
    "            if 't' in line[1] and line[3]=='t':\n",
    "                target_hit+=1\n",
    "            if 't' in line[1] and line[3]=='f':\n",
    "                target_miss+=1\n",
    "            # Start move to lure trials\n",
    "            if 's' in line[1]:\n",
    "                lure+=1\n",
    "            if 's' in line[1] and line[3]=='t':\n",
    "                lure_fa+=1\n",
    "            if 's' in line[1] and line[3]=='f':\n",
    "                lure_cr+=1\n",
    "            if 'n' in line[1]:\n",
    "                foil+=1\n",
    "            if 'n' in line[1] and line[3]=='t':\n",
    "                foil_fa+=1\n",
    "            if 'n' in line[1] and line[3]=='f':\n",
    "                foil_cr+=1\n",
    "            if line [1] == '':\n",
    "                junk+=1\n",
    "            \n",
    "    target_hit = target_hit\n",
    "    target_miss = target_miss\n",
    "    lure_cr = lure_cr\n",
    "    lure_fa = lure_fa\n",
    "    target_hit_rate = target_hit / (target)\n",
    "    fa_cr_rate = foil_cr / (foil)\n",
    "    target_miss_rate = target_miss/target\n",
    "    lure_cr_rate = lure_cr/lure\n",
    "    lure_fa_rate = lure_fa/lure\n",
    "    foil_cr_rate = foil_cr/foil\n",
    "    foil_fa_rate = foil_fa/foil\n",
    "    cr = lure_cr + foil_cr\n",
    "    cr_rate = (lure_cr + foil_cr)/(lure + foil)\n",
    "    fa = lure_fa + foil_fa\n",
    "    fa_rate = (lure_fa + foil_fa)/(lure + foil)\n",
    "    \n",
    "    if target_hit_rate == 1: \n",
    "        target_hit_rate = (target - 0.5) / (target)\n",
    "    if target_hit_rate == 0: \n",
    "        target_hit_rate = 0.5 / (target)\n",
    "        \n",
    "    if foil_fa_rate == 1: \n",
    "        foil_fa_rate = (foil - 0.5) / (foil)\n",
    "    if foil_fa_rate == 0: \n",
    "        foil_fa_rate = 0.5 / (foil)    \n",
    "    \n",
    "    dprime = Z(target_hit_rate) - Z(foil_fa_rate)\n",
    "    dprime_lures = Z(target_hit_rate) - Z(lure_fa_rate)\n",
    "    \n",
    "    LDI = lure_cr_rate - target_miss_rate\n",
    "    \n",
    "    LDI_reviewer = lure_cr_rate - foil_fa_rate\n",
    "    \n",
    "    beta = math.exp((Z(fa_rate)**2 - Z(target_hit_rate)**2) / 2)\n",
    "    c = -(Z(target_hit_rate) + Z(fa_rate)) / 2\n",
    "    ad = norm.cdf(dprime / math.sqrt(2))\n",
    "    \n",
    "    # Append our big data frame with each subject's data\n",
    "    \n",
    "    sub_all_group_younger_desc_narrative = sub_all_group_younger_desc_narrative.append(pd.DataFrame\\\n",
    "    ({'subject': subject, 'target_hit': target_hit, 'target_miss': target_miss,\\\n",
    "      'lure_cr': lure_cr, 'lure_fa': lure_fa,\\\n",
    "      'foil_cr': foil_cr, 'foil_fa':foil_fa,\\\n",
    "      'target_hit_rate': target_hit_rate, 'lure_cr_rate': lure_cr_rate,'foil_cr_rate': foil_cr_rate,\\\n",
    "      'lure_fa_rate': lure_fa_rate, 'foil_fa_rate':foil_fa_rate,\\\n",
    "      'cr': cr, 'cr_rate': cr_rate, 'fa': fa,'fa_rate': fa_rate,\\\n",
    "      'dprime':dprime, 'dprime_lures':dprime_lures, 'LDI':LDI, 'LDI_reviewer':LDI_reviewer, 'beta':beta, 'c':c, 'ad':ad}, index=[0]), ignore_index=True)\n",
    "\n",
    "#     Append performance summary file\n",
    "    narrative_summary.write(\"%d,%d,%d,%d,%d,%d,%d,%d,%d,%d\\n\\n\\n\\n\" %(target,target_hit,target_miss,lure,lure_cr,lure_fa,foil,foil_cr,foil_fa,junk))\n",
    "    narrative_summary.write(\"targets\\n\\ntarget_hit_rate,target_miss_rate\\n\")\n",
    "    narrative_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(target_hit_rate,target_miss_rate))\n",
    "    narrative_summary.write(\"lures\\n\\nlure_cr_rate,lure_fa_rate\\n\")\n",
    "    narrative_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(lure_cr_rate,lure_fa_rate))\n",
    "    narrative_summary.write(\"foils\\n\\nfoil_cr_rate,foil_fa_rate\\n\")\n",
    "    narrative_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(foil_cr_rate,foil_fa_rate))\n",
    "    narrative_summary.close()\n",
    "    print(\"narrative_summary created successfully for %s\" %(subject))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perceptual_summary created successfully for 301\n",
      "perceptual_summary created successfully for 302\n",
      "perceptual_summary created successfully for 303\n",
      "perceptual_summary created successfully for 304\n",
      "perceptual_summary created successfully for 305\n",
      "perceptual_summary created successfully for 306\n",
      "perceptual_summary created successfully for 307\n",
      "perceptual_summary created successfully for 308\n",
      "perceptual_summary created successfully for 309\n",
      "perceptual_summary created successfully for 310\n",
      "perceptual_summary created successfully for 311\n",
      "perceptual_summary created successfully for 312\n",
      "perceptual_summary created successfully for 313\n",
      "perceptual_summary created successfully for 314\n",
      "perceptual_summary created successfully for 315\n",
      "perceptual_summary created successfully for 316\n",
      "perceptual_summary created successfully for 317\n",
      "perceptual_summary created successfully for 318\n",
      "perceptual_summary created successfully for 319\n",
      "perceptual_summary created successfully for 320\n",
      "perceptual_summary created successfully for 321\n"
     ]
    }
   ],
   "source": [
    "sub_all_group_younger_desc_perceptual = pd.DataFrame(columns=['subject', 'target_hit', 'lure_cr','foil_cr'])\n",
    "\n",
    "for subject in sublist_younger: \n",
    "    perceptual_summary = open(os.path.join(output_dir, f'sub-{subject}_group-younger_task-recognition_desc-perceptual_results.txt'), 'w')\n",
    "    perceptual_summary.write('subject: %d\\n' %(subject))\n",
    "    perceptual_summary.write('performance_summary\\n\\n\\n\\nraw_data\\n\\n')\n",
    "    perceptual_summary.write('target,target_hit,target_miss,lure,lure_cr,lure_fa,foil,foil_cr,foil_fa,junk\\n')\n",
    "    \n",
    "    performance=[]\n",
    "    target=0\n",
    "    target_hit=0\n",
    "    target_miss=0\n",
    "    lure=0\n",
    "    lure_cr=0\n",
    "    lure_fa=0\n",
    "    foil=0\n",
    "    foil_cr=0\n",
    "    foil_fa=0\n",
    "    junk=0\n",
    "    \n",
    "    with open(os.path.join(data_dir, f'sub-{subject}_group-younger_task-recognition_desc-perceptual.txt')) as fd:\n",
    "        for line in islice(csv.reader(fd), 5, None):\n",
    "            performance.append([line[0],line[1],line[2],line[3],line[4]])\n",
    "            if 't' in line[1]:\n",
    "                target+=1\n",
    "            if 't' in line[1] and line[3]=='t':\n",
    "                target_hit+=1\n",
    "            if 't' in line[1] and line[3]=='f':\n",
    "                target_miss+=1\n",
    "            # Start move to lure trials\n",
    "            if 's' in line[1]:\n",
    "                lure+=1\n",
    "            if 's' in line[1] and line[3]=='t':\n",
    "                lure_fa+=1\n",
    "            if 's' in line[1] and line[3]=='f':\n",
    "                lure_cr+=1\n",
    "            if 'd' in line[1]:\n",
    "                foil+=1\n",
    "            if 'd' in line[1] and line[3]=='t':\n",
    "                foil_fa+=1\n",
    "            if 'd' in line[1] and line[3]=='f':\n",
    "                foil_cr+=1\n",
    "            if line [1] == '':\n",
    "                junk+=1\n",
    "            \n",
    "    target_hit = target_hit\n",
    "    target_miss = target_miss\n",
    "    lure_cr = lure_cr\n",
    "    lure_fa = lure_fa\n",
    "    target_hit_rate = target_hit / (target)\n",
    "    fa_cr_rate = foil_cr / (foil)\n",
    "    target_miss_rate = target_miss/target\n",
    "    lure_cr_rate = lure_cr/lure\n",
    "    lure_fa_rate = lure_fa/lure\n",
    "    foil_cr_rate = foil_cr/foil\n",
    "    foil_fa_rate = foil_fa/foil\n",
    "    cr = lure_cr + foil_cr\n",
    "    cr_rate = (lure_cr + foil_cr)/(lure + foil)\n",
    "    fa = lure_fa + foil_fa\n",
    "    fa_rate = (lure_fa + foil_fa)/(lure + foil)\n",
    "    \n",
    "    if target_hit_rate == 1: \n",
    "        target_hit_rate = (target - 0.5) / (target)\n",
    "    if target_hit_rate == 0: \n",
    "        target_hit_rate = 0.5 / (target)\n",
    "        \n",
    "    if foil_fa_rate == 1: \n",
    "        foil_fa_rate = (foil - 0.5) / (foil)\n",
    "    if foil_fa_rate == 0: \n",
    "        foil_fa_rate = 0.5 / (foil)    \n",
    "    \n",
    "    dprime = Z(target_hit_rate) - Z(foil_fa_rate)\n",
    "    dprime_lures = Z(target_hit_rate) - Z(lure_fa_rate)\n",
    "    \n",
    "    LDI = lure_cr_rate - target_miss_rate\n",
    "    \n",
    "    LDI_reviewer = lure_cr_rate - foil_fa_rate\n",
    "    \n",
    "    beta = math.exp((Z(fa_rate)**2 - Z(target_hit_rate)**2) / 2)\n",
    "    c = -(Z(target_hit_rate) + Z(fa_rate)) / 2\n",
    "    ad = norm.cdf(dprime / math.sqrt(2))\n",
    "    \n",
    "    # Append our big data frame with each subject's data\n",
    "    \n",
    "    sub_all_group_younger_desc_perceptual = sub_all_group_younger_desc_perceptual.append(pd.DataFrame\\\n",
    "    ({'subject': subject, 'target_hit': target_hit, 'target_miss': target_miss,\\\n",
    "      'lure_cr': lure_cr, 'lure_fa': lure_fa,\\\n",
    "      'foil_cr': foil_cr, 'foil_fa':foil_fa,\\\n",
    "      'target_hit_rate': target_hit_rate, 'lure_cr_rate': lure_cr_rate,'foil_cr_rate': foil_cr_rate,\\\n",
    "      'lure_fa_rate': lure_fa_rate, 'foil_fa_rate':foil_fa_rate,\\\n",
    "      'cr': cr, 'cr_rate': cr_rate, 'fa': fa,'fa_rate': fa_rate,\\\n",
    "      'dprime':dprime, 'dprime_lures':dprime_lures, 'LDI':LDI, 'LDI_reviewer':LDI_reviewer, 'beta':beta, 'c':c, 'ad':ad}, index=[0]), ignore_index=True)\n",
    "\n",
    "    #Append performance summary file\n",
    "    perceptual_summary.write(\"%d,%d,%d,%d,%d,%d,%d,%d,%d,%d\\n\\n\\n\\n\" %(target,target_hit,target_miss,lure,lure_cr,lure_fa,foil,foil_cr,foil_fa,junk))\n",
    "    perceptual_summary.write(\"targets\\n\\ntarget_hit_rate,target_miss_rate\\n\")\n",
    "    perceptual_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(target_hit_rate,target_miss_rate))\n",
    "    perceptual_summary.write(\"lures\\n\\nlure_cr_rate,lure_fa_rate\\n\")\n",
    "    perceptual_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(lure_cr_rate,lure_fa_rate))\n",
    "    perceptual_summary.write(\"foils\\n\\nfoil_cr_rate,foil_fa_rate\\n\")\n",
    "    perceptual_summary.write(\"%.3f,%.3f\\n\\n\\n\"%(foil_cr_rate,foil_fa_rate))\n",
    "    perceptual_summary.close()\n",
    "    print(\"perceptual_summary created successfully for %s\" %(subject))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append Older and Younger Adults' Output files together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>target_hit</th>\n",
       "      <th>lure_cr</th>\n",
       "      <th>foil_cr</th>\n",
       "      <th>target_miss</th>\n",
       "      <th>lure_fa</th>\n",
       "      <th>foil_fa</th>\n",
       "      <th>target_hit_rate</th>\n",
       "      <th>lure_cr_rate</th>\n",
       "      <th>foil_cr_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>fa_rate</th>\n",
       "      <th>dprime</th>\n",
       "      <th>dprime_lures</th>\n",
       "      <th>LDI</th>\n",
       "      <th>LDI_reviewer</th>\n",
       "      <th>beta</th>\n",
       "      <th>c</th>\n",
       "      <th>ad</th>\n",
       "      <th>group</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>3.409597</td>\n",
       "      <td>2.392323</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.357225</td>\n",
       "      <td>0.109767</td>\n",
       "      <td>0.992044</td>\n",
       "      <td>older</td>\n",
       "      <td>narrative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3.961960</td>\n",
       "      <td>2.264642</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.297105</td>\n",
       "      <td>-0.433247</td>\n",
       "      <td>0.997457</td>\n",
       "      <td>older</td>\n",
       "      <td>narrative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>203</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>2.675536</td>\n",
       "      <td>1.569535</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.300493</td>\n",
       "      <td>0.134575</td>\n",
       "      <td>0.970747</td>\n",
       "      <td>older</td>\n",
       "      <td>narrative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>2.652446</td>\n",
       "      <td>1.635172</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>2.688898</td>\n",
       "      <td>0.488343</td>\n",
       "      <td>0.969642</td>\n",
       "      <td>older</td>\n",
       "      <td>narrative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>2.801336</td>\n",
       "      <td>1.695335</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.160620</td>\n",
       "      <td>0.071675</td>\n",
       "      <td>0.976196</td>\n",
       "      <td>older</td>\n",
       "      <td>narrative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>317</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.961960</td>\n",
       "      <td>2.087262</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.265150</td>\n",
       "      <td>-0.496147</td>\n",
       "      <td>0.997457</td>\n",
       "      <td>younger</td>\n",
       "      <td>perceptual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>318</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.629131</td>\n",
       "      <td>2.342707</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.736797</td>\n",
       "      <td>-0.109767</td>\n",
       "      <td>0.994859</td>\n",
       "      <td>younger</td>\n",
       "      <td>perceptual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>319</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>4.256090</td>\n",
       "      <td>3.629131</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.558407</td>\n",
       "      <td>-0.147065</td>\n",
       "      <td>0.998692</td>\n",
       "      <td>younger</td>\n",
       "      <td>perceptual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>320</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>3.629131</td>\n",
       "      <td>3.002172</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.741927</td>\n",
       "      <td>0.166414</td>\n",
       "      <td>0.994859</td>\n",
       "      <td>younger</td>\n",
       "      <td>perceptual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>321</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3.961960</td>\n",
       "      <td>2.264642</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.297105</td>\n",
       "      <td>-0.433247</td>\n",
       "      <td>0.997457</td>\n",
       "      <td>younger</td>\n",
       "      <td>perceptual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject target_hit lure_cr foil_cr  target_miss  lure_fa  foil_fa  \\\n",
       "0      201         27      26      30          3.0      4.0      0.0   \n",
       "1      202         29      20      30          1.0     10.0      0.0   \n",
       "2      203         24      23      29          6.0      7.0      1.0   \n",
       "3      204         21      26      30          9.0      4.0      0.0   \n",
       "4      205         25      23      29          5.0      7.0      1.0   \n",
       "..     ...        ...     ...     ...          ...      ...      ...   \n",
       "16     317         29      18      30          1.0     12.0      0.0   \n",
       "17     318         28      24      30          2.0      6.0      0.0   \n",
       "18     319         30      28      30          0.0      2.0      0.0   \n",
       "19     320         28      28      30          2.0      2.0      0.0   \n",
       "20     321         29      20      30          1.0     10.0      0.0   \n",
       "\n",
       "    target_hit_rate  lure_cr_rate  foil_cr_rate  ...   fa_rate    dprime  \\\n",
       "0          0.900000      0.866667      1.000000  ...  0.066667  3.409597   \n",
       "1          0.966667      0.666667      1.000000  ...  0.166667  3.961960   \n",
       "2          0.800000      0.766667      0.966667  ...  0.133333  2.675536   \n",
       "3          0.700000      0.866667      1.000000  ...  0.066667  2.652446   \n",
       "4          0.833333      0.766667      0.966667  ...  0.133333  2.801336   \n",
       "..              ...           ...           ...  ...       ...       ...   \n",
       "16         0.966667      0.600000      1.000000  ...  0.200000  3.961960   \n",
       "17         0.933333      0.800000      1.000000  ...  0.100000  3.629131   \n",
       "18         0.983333      0.933333      1.000000  ...  0.033333  4.256090   \n",
       "19         0.933333      0.933333      1.000000  ...  0.033333  3.629131   \n",
       "20         0.966667      0.666667      1.000000  ...  0.166667  3.961960   \n",
       "\n",
       "    dprime_lures       LDI  LDI_reviewer      beta         c        ad  \\\n",
       "0       2.392323  0.766667      0.850000  1.357225  0.109767  0.992044   \n",
       "1       2.264642  0.633333      0.650000  0.297105 -0.433247  0.997457   \n",
       "2       1.569535  0.566667      0.733333  1.300493  0.134575  0.970747   \n",
       "3       1.635172  0.566667      0.850000  2.688898  0.488343  0.969642   \n",
       "4       1.695335  0.600000      0.733333  1.160620  0.071675  0.976196   \n",
       "..           ...       ...           ...       ...       ...       ...   \n",
       "16      2.087262  0.566667      0.583333  0.265150 -0.496147  0.997457   \n",
       "17      2.342707  0.733333      0.783333  0.736797 -0.109767  0.994859   \n",
       "18      3.629131  0.933333      0.916667  0.558407 -0.147065  0.998692   \n",
       "19      3.002172  0.866667      0.916667  1.741927  0.166414  0.994859   \n",
       "20      2.264642  0.633333      0.650000  0.297105 -0.433247  0.997457   \n",
       "\n",
       "      group        type  \n",
       "0     older   narrative  \n",
       "1     older   narrative  \n",
       "2     older   narrative  \n",
       "3     older   narrative  \n",
       "4     older   narrative  \n",
       "..      ...         ...  \n",
       "16  younger  perceptual  \n",
       "17  younger  perceptual  \n",
       "18  younger  perceptual  \n",
       "19  younger  perceptual  \n",
       "20  younger  perceptual  \n",
       "\n",
       "[84 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_all_group_older_desc_narrative[\"group\"] = \"older\"\n",
    "sub_all_group_older_desc_perceptual[\"group\"] = \"older\"\n",
    "sub_all_group_younger_desc_narrative[\"group\"] = \"younger\"\n",
    "sub_all_group_younger_desc_perceptual[\"group\"] = \"younger\"\n",
    "\n",
    "sub_all_group_older_desc_narrative[\"type\"] = \"narrative\"\n",
    "sub_all_group_older_desc_perceptual[\"type\"] = \"perceptual\"\n",
    "sub_all_group_younger_desc_narrative[\"type\"] = \"narrative\"\n",
    "sub_all_group_younger_desc_perceptual[\"type\"] = \"perceptual\"\n",
    "\n",
    "sub_all_group_all_desc_narrative = pd.concat([sub_all_group_older_desc_narrative, sub_all_group_younger_desc_narrative])\n",
    "sub_all_group_all_desc_perceptual = pd.concat([sub_all_group_older_desc_perceptual, sub_all_group_younger_desc_perceptual])\n",
    "\n",
    "sub_all_group_older = pd.concat([sub_all_group_older_desc_narrative, sub_all_group_older_desc_perceptual])\n",
    "sub_all_group_younger = pd.concat([sub_all_group_younger_desc_narrative, sub_all_group_younger_desc_perceptual])\n",
    "\n",
    "sub_all_group_all_desc_all = pd.concat([sub_all_group_all_desc_narrative, sub_all_group_all_desc_perceptual])\n",
    "sub_all_group_all_desc_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add neuropsychological test results on exisiting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuropsych = pd.read_csv(os.path.join(base_dir, 'data/neuropsych/neuropsych_scores.csv'))\n",
    "#neuropsych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_all_group_older = pd.merge(sub_all_group_older, neuropsych, left_on='subject', right_on='subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_all_group_all_desc_recog_neuropsych = pd.concat([sub_all_group_older, sub_all_group_younger])\n",
    "#sub_all_group_all_desc_recog_neuropsych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_all_group_all_desc_recog_neuropsych[\"group_type\"] = sub_all_group_all_desc_recog_neuropsych[\"group\"] + \"_\" +sub_all_group_all_desc_recog_neuropsych[\"type\"]\n",
    "#sub_all_group_all_desc_recog_neuropsych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export appended dataframe to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_all_group_younger_desc_narrative.to_csv(os.path.join(output_dir, f'sub-all_group-younger_task-recognition_desc-narrative_results.csv'), index = None, header=True)\n",
    "sub_all_group_younger_desc_perceptual.to_csv(os.path.join(output_dir, f'sub-all_group-younger_task-recognition_desc-perceptual_results.csv'), index = None, header=True)\n",
    "sub_all_group_older_desc_narrative.to_csv(os.path.join(output_dir, f'sub-all_group-older_task-recognition_desc-narrative_results.csv'), index = None, header=True)\n",
    "sub_all_group_older_desc_perceptual.to_csv(os.path.join(output_dir, f'sub-all_group-older_task-recognition_desc-perceptual_results.csv'), index = None, header=True)\n",
    "sub_all_group_all_desc_narrative.to_csv(os.path.join(output_dir, f'sub-all_group-all_task-recognition_desc-narrative_results.csv'), index = None, header=True)\n",
    "sub_all_group_all_desc_perceptual.to_csv(os.path.join(output_dir, f'sub-all_group-all_task-recognition_desc-perceptual_results.csv'), index = None, header=True)\n",
    "sub_all_group_all_desc_all.to_csv(os.path.join(output_dir, f'sub-all_group-all_task-recognition_desc-all_results.csv'), index = None, header=True)\n",
    "sub_all_group_all_desc_recog_neuropsych.to_csv(os.path.join(output_dir, f'sub-all_group-all_task-recognition_desc-all_results_neuropsych.csv'), index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
